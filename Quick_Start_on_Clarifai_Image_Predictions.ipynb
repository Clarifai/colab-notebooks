{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7nD65mrlsPP"
   },
   "source": [
    "# Quick Start with Clarifai\n",
    "\n",
    "![Clarifai logo](https://www.clarifai.com/hs-fs/hubfs/logo/Clarifai/clarifai-740x150.png?width=240)\n",
    "\n",
    "This is a self-contained notebook that shows how to run Clarifai models with your account credentials and start getting insights from your images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pdqgUA0mG8c"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Clarifai/colab-notebooks/blob/main/Quick_Start_on_Clarifai_Image_Predictions.ipynb)\n",
    "\n",
    "## Get Started \n",
    "\n",
    "*  Install Clarifai gRPC client for Python and the latest protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGVi7YDjmAGN",
    "outputId": "572dc190-5588-4f2a-dbeb-4a93a3192127"
   },
   "outputs": [],
   "source": [
    "!pip install -q clarifai-grpc && pip install --upgrade --no-deps -q protobuf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PliqEoAEmjlf"
   },
   "source": [
    "*   Install other dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1B1Ipm6Gmlqb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import skimage \n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEYxsT_7eJOJ"
   },
   "source": [
    "## Initialize the Clarifai gRPC-based client\n",
    "Let's import the gRPC-based objects needed to communicate with the Clarifai platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNbucu7snokY"
   },
   "outputs": [],
   "source": [
    "from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "from clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\n",
    "from clarifai_grpc.grpc.api.status import status_pb2, status_code_pb2\n",
    "\n",
    "# Construct the communications channel \n",
    "channel = ClarifaiChannel.get_grpc_channel()\n",
    "# Construct the V2Stub object for accessing all the Clarifai API functionality\n",
    "stub = service_pb2_grpc.V2Stub(channel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9aCvEy6gbDY"
   },
   "source": [
    "## Set up Authorization\n",
    "\n",
    "Set up the metadata object that’s used to authenticate your access to the Clarifai platform.\n",
    "\n",
    "To create or find a PAT, in Clarifai Community, click on the circular icon for your username in the top right, select “Security”, and then create a PAT or copy an existing one if you’ve already created one. You can follow the below screenshots to see where to find and create PATs.\n",
    "\n",
    "You can find more information on [this page](https://docs.clarifai.com/clarifai-basics/authentication/authorize/).\n",
    "\n",
    "<img src=\"images/notebook1-sk.jpg\" alt=\"drawing\" width=\"800\" height=\"750\"/>\n",
    "<img src=\"images/notebook2-sk.jpg\" alt=\"drawing\" width=\"800\" height=\"750\"/>\n",
    "\n",
    "\n",
    "<!-- ![](images/notebook1-sk.jpg) -->\n",
    "<!-- ![](images/notebook2-sk.jpg) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT = 'YOUR_PAT_HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giuvkD3Fh5ZN"
   },
   "outputs": [],
   "source": [
    "USER_ID = 'clarifai'\n",
    "APP_ID = 'main'\n",
    "\n",
    "metadata = (('authorization', 'Key ' + PAT),)\n",
    "userDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbnkDUMDqmSH"
   },
   "source": [
    "## Collect Your Inputs\n",
    "\n",
    "Let's grab the images we'll use for making the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "V5NQA-Xpm2T_",
    "outputId": "b99762ff-9a6b-449c-dab3-594fa475eb75"
   },
   "outputs": [],
   "source": [
    "# images in skimage to use\n",
    "descriptions = [\n",
    "    \"page\",\n",
    "    \"chelsea\",\n",
    "    \"astronaut\",\n",
    "    \"rocket\",\n",
    "    \"motorcycle_right\",\n",
    "    \"camera\",\n",
    "    \"horse\", \n",
    "    \"coffee\"\n",
    "]\n",
    "\n",
    "original_images = []\n",
    "images = []\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "for filename in [filename for filename in os.listdir(skimage.data_dir) if filename.endswith(\".png\") or filename.endswith(\".jpg\")]:\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    if name not in descriptions:\n",
    "        continue\n",
    "\n",
    "    image = Image.open(os.path.join(skimage.data_dir, filename)).convert(\"RGB\")\n",
    "  \n",
    "    plt.subplot(2, 4, len(images) + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"{filename}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    original_images.append(image)\n",
    "    images.append(image)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98sIxFhLl2Kt"
   },
   "source": [
    "## Prepare Your Inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcScUBlktYQv"
   },
   "source": [
    "Let's convert the images into Input objects for batch prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9m6KzJKgtEy-"
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for image in images:\n",
    "  buffered = BytesIO()\n",
    "  image.save(buffered, format=\"PNG\")\n",
    "  inputs.append(\n",
    "      resources_pb2.Input(\n",
    "          data=resources_pb2.Data(\n",
    "              image=resources_pb2.Image(\n",
    "                  base64=buffered.getvalue()\n",
    "              )\n",
    "          )\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5DGyQ6Hmo1s"
   },
   "source": [
    "## Make Predictions\n",
    "The Clarifai's  [General Model](https://clarifai.com/clarifai/main/models/general-image-recognition) is a visual classifier for identifying a variety of concepts, common objects, etc. It is a great all-purpose solution for most visual recognition needs with industry-leading performance. It works on both images and videos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvhV53DVsuDL"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = 'general-image-recognition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6poRlvIsmAD"
   },
   "outputs": [],
   "source": [
    "post_model_outputs_response = stub.PostModelOutputs(\n",
    "    service_pb2.PostModelOutputsRequest(\n",
    "        user_app_id=userDataObject,  # The userDataObject is created in the overview and is required when using a PAT\n",
    "        model_id=MODEL_ID,\n",
    "        inputs=inputs\n",
    "    ),\n",
    "    metadata=metadata\n",
    ")\n",
    "if post_model_outputs_response.status.code != status_code_pb2.SUCCESS:\n",
    "    print(post_model_outputs_response.status)\n",
    "    raise Exception(\"Post model outputs failed, status: \" + post_model_outputs_response.status.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGHD-clArkfM"
   },
   "source": [
    "## Generate Visual Diagrams\n",
    "Let's plot diagrams that showcase the identified concepts against the propability of their occurence in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "id": "bwUJkRIOm4Rv",
    "outputId": "03d45b54-2d6d-4e09-84cb-41d2e3793971"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "\n",
    "for i, (image, output) in enumerate(zip(original_images, post_model_outputs_response.outputs)):\n",
    "    top_preds = {\n",
    "      concept.name: concept.value for concept in output.data.concepts[:5]\n",
    "    }\n",
    "    plt.subplot(4, 4, 2 * i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(4, 4, 2 * i + 2)\n",
    "    y = np.arange(len(top_preds))\n",
    "    plt.grid()\n",
    "    plt.barh(y, list(top_preds.values()))\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.yticks(y, list(top_preds.keys()))\n",
    "    plt.xlabel(\"probability\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.6)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "00438606d8d9db4e5e1de1f23c45b3b3b1f9e5c34b1a5f3389326fcc9394556a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
